{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FASE 2\n",
    "\n",
    "- Los casos de rabia ya no seran nodos solo seran atributos de las cuadras.\n",
    "- Las cuadras tendran atributos del caso de rabia y de la proximidad de los casos de rabia a X metros\n",
    "- Vamos a crear 2 grafos uno para entrenamiento y validacion con los datos del 2015 hasta el 2021 y otro para test con los datos del 2022 hasta el 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadr in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (0.5.3)\n",
      "Requirement already satisfied: pandas in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: fastkml in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: torch_geometric in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: folium in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (0.18.0)\n",
      "Requirement already satisfied: geopandas in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: filelock in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: arrow in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from fastkml) (1.3.0)\n",
      "Requirement already satisfied: pygeoif>=1.5 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from fastkml) (1.5.1)\n",
      "Requirement already satisfied: aiohttp in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch_geometric) (3.12.13)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch_geometric) (6.0.0)\n",
      "Requirement already satisfied: pyparsing in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: requests in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: branca>=0.6.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from folium) (0.8.0)\n",
      "Requirement already satisfied: xyzservices in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from folium) (2024.9.0)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from geopandas) (1.10.1)\n",
      "Requirement already satisfied: packaging in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from geopandas) (24.1)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from geopandas) (3.7.0)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from geopandas) (2.0.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (24.2.0)\n",
      "Requirement already satisfied: certifi in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (2024.8.30)\n",
      "Requirement already satisfied: click~=8.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from jinja2->torch) (3.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.20.1)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from arrow->fastkml) (2.9.0.20241003)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyreadr pandas torch fastkml torch_geometric folium geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>n_microred</th>\n",
       "      <th>microred</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>y_proj</th>\n",
       "      <th>x_proj</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>20</td>\n",
       "      <td>MARITZA CAMPOS</td>\n",
       "      <td>C.S. MARITZA CAMPO DIAZ</td>\n",
       "      <td>-16.351375</td>\n",
       "      <td>-71.562525</td>\n",
       "      <td>-1935159.862</td>\n",
       "      <td>2835969.968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.0</td>\n",
       "      <td>20</td>\n",
       "      <td>MARITZA CAMPOS</td>\n",
       "      <td>P.S. CIUDAD MUNICIPAL</td>\n",
       "      <td>-16.325474</td>\n",
       "      <td>-71.594062</td>\n",
       "      <td>-1931722.877</td>\n",
       "      <td>2832729.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>20</td>\n",
       "      <td>MARITZA CAMPOS</td>\n",
       "      <td>P.S. PERUARBO</td>\n",
       "      <td>-16.345310</td>\n",
       "      <td>-71.600061</td>\n",
       "      <td>-1933977.297</td>\n",
       "      <td>2831792.294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>20</td>\n",
       "      <td>MARITZA CAMPOS</td>\n",
       "      <td>P.S. NAZARENO</td>\n",
       "      <td>-16.328171</td>\n",
       "      <td>-71.549513</td>\n",
       "      <td>-1932597.555</td>\n",
       "      <td>2837747.160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FRANCISCO BOLOGNESI</td>\n",
       "      <td>C.S. FRANCISCO BOLOGNESI</td>\n",
       "      <td>-16.354767</td>\n",
       "      <td>-71.542092</td>\n",
       "      <td>-1935814.847</td>\n",
       "      <td>2838243.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster  n_microred             microred                      name  \\\n",
       "0     22.0          20       MARITZA CAMPOS   C.S. MARITZA CAMPO DIAZ   \n",
       "1     26.0          20       MARITZA CAMPOS     P.S. CIUDAD MUNICIPAL   \n",
       "2     22.0          20       MARITZA CAMPOS             P.S. PERUARBO   \n",
       "3     24.0          20       MARITZA CAMPOS             P.S. NAZARENO   \n",
       "4      5.0           1  FRANCISCO BOLOGNESI  C.S. FRANCISCO BOLOGNESI   \n",
       "\n",
       "         lat       long       y_proj       x_proj Unnamed: 8 Unnamed: 9  \\\n",
       "0 -16.351375 -71.562525 -1935159.862  2835969.968        NaN        NaN   \n",
       "1 -16.325474 -71.594062 -1931722.877  2832729.607        NaN        NaN   \n",
       "2 -16.345310 -71.600061 -1933977.297  2831792.294        NaN        NaN   \n",
       "3 -16.328171 -71.549513 -1932597.555  2837747.160        NaN        NaN   \n",
       "4 -16.354767 -71.542092 -1935814.847  2838243.050        NaN        NaN   \n",
       "\n",
       "  Unnamed: 10  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PUESTOS DE SALUD\n",
    "df_health_posts = pd.read_csv(\"~/Descargas/SPATIAL_DATA_AQP/Health_centers_AQP/Puestos_de_salud_APQ_12ene2024.csv\", sep=\";\")\n",
    "print(df_health_posts.shape)\n",
    "df_health_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>ident</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>y_proj</th>\n",
       "      <th>x_proj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rios_Principales</td>\n",
       "      <td>r_prin_001</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1.516416e+00</td>\n",
       "      <td>2.076337e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rios_Principales</td>\n",
       "      <td>r_prin_001</td>\n",
       "      <td>-16.30381616</td>\n",
       "      <td>-71.48611168</td>\n",
       "      <td>-1.930532e+06</td>\n",
       "      <td>2.845257e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rios_Principales</td>\n",
       "      <td>r_prin_001</td>\n",
       "      <td>-16.30379005</td>\n",
       "      <td>-71.48621225</td>\n",
       "      <td>-1.930528e+06</td>\n",
       "      <td>2.845246e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rios_Principales</td>\n",
       "      <td>r_prin_001</td>\n",
       "      <td>-16.30376392</td>\n",
       "      <td>-71.48631287</td>\n",
       "      <td>-1.930523e+06</td>\n",
       "      <td>2.845235e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rios_Principales</td>\n",
       "      <td>r_prin_001</td>\n",
       "      <td>-16.30376396</td>\n",
       "      <td>-71.48641297</td>\n",
       "      <td>-1.930522e+06</td>\n",
       "      <td>2.845224e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               type       ident           lat          long        y_proj  \\\n",
       "0  Rios_Principales  r_prin_001                             -1.516416e+00   \n",
       "1  Rios_Principales  r_prin_001  -16.30381616  -71.48611168 -1.930532e+06   \n",
       "2  Rios_Principales  r_prin_001  -16.30379005  -71.48621225 -1.930528e+06   \n",
       "3  Rios_Principales  r_prin_001  -16.30376392  -71.48631287 -1.930523e+06   \n",
       "4  Rios_Principales  r_prin_001  -16.30376396  -71.48641297 -1.930522e+06   \n",
       "\n",
       "         x_proj  \n",
       "0  2.076337e+07  \n",
       "1  2.845257e+06  \n",
       "2  2.845246e+06  \n",
       "3  2.845235e+06  \n",
       "4  2.845224e+06  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TORRENTERAS\n",
    "df_water_channels = pd.read_csv(\"~/Descargas/SPATIAL_DATA_AQP/Water_channels_AQP/Hidrografia_AQP_18ene2024.csv\", sep=\";\")\n",
    "df_water_channels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>y_proj</th>\n",
       "      <th>x_proj</th>\n",
       "      <th>ingreso_economico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4.54-1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1.516416e+00</td>\n",
       "      <td>2.076337e+07</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4.54-1</td>\n",
       "      <td>-16.3619287</td>\n",
       "      <td>-71.56312249</td>\n",
       "      <td>-1.936392e+06</td>\n",
       "      <td>2.835765e+06</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4.54-1</td>\n",
       "      <td>-16.36042421</td>\n",
       "      <td>-71.56334575</td>\n",
       "      <td>-1.936212e+06</td>\n",
       "      <td>2.835759e+06</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.4.54-1</td>\n",
       "      <td>-16.36114067</td>\n",
       "      <td>-71.56646806</td>\n",
       "      <td>-1.936257e+06</td>\n",
       "      <td>2.835396e+06</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4.54-1</td>\n",
       "      <td>-16.36256118</td>\n",
       "      <td>-71.5660744</td>\n",
       "      <td>-1.936429e+06</td>\n",
       "      <td>2.835422e+06</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ident           lat          long        y_proj        x_proj  \\\n",
       "0  1.4.54-1                             -1.516416e+00  2.076337e+07   \n",
       "1  1.4.54-1   -16.3619287  -71.56312249 -1.936392e+06  2.835765e+06   \n",
       "2  1.4.54-1  -16.36042421  -71.56334575 -1.936212e+06  2.835759e+06   \n",
       "3  1.4.54-1  -16.36114067  -71.56646806 -1.936257e+06  2.835396e+06   \n",
       "4  1.4.54-1  -16.36256118   -71.5660744 -1.936429e+06  2.835422e+06   \n",
       "\n",
       "  ingreso_economico  \n",
       "0                 B  \n",
       "1                 B  \n",
       "2                 B  \n",
       "3                 B  \n",
       "4                 B  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  NIVEL SOCIO-ECONOMICO\n",
    "df_economic_income_1 = pd.read_csv(\"~/Descargas/SPATIAL_DATA_AQP/Economic_income_AQP/Economic_income_cluster/Ecom_cluster_22_10may2023.csv\", sep=\";\")\n",
    "df_economic_income_2 = pd.read_csv(\"~/Descargas/SPATIAL_DATA_AQP/Economic_income_AQP/Economic_income_cluster/Ecom_cluster_23_21feb2023.csv\", sep=\";\")\n",
    "df_economic_income_3 = pd.read_csv(\"~/Descargas/SPATIAL_DATA_AQP/Economic_income_AQP/Economic_income_cluster/Ecom_cluster_24_21feb2023.csv\", sep=\";\")\n",
    "df_economic_income_4 = pd.read_csv(\"~/Descargas/SPATIAL_DATA_AQP/Economic_income_AQP/Economic_income_cluster/Ecom_cluster_25_21feb2023.csv\", sep=\";\")\n",
    "df_economic_income_5 = pd.read_csv(\"~/Descargas/SPATIAL_DATA_AQP/Economic_income_AQP/Economic_income_cluster/Ecom_cluster_26_21feb2023.csv\", sep=\";\")\n",
    "df_economic_income_6 = pd.read_csv(\"~/Descargas/SPATIAL_DATA_AQP/Economic_income_AQP/Economic_income_cluster/Ecom_cluster_27_21feb2023.csv\", sep=\";\")\n",
    "df_economic_income = pd.concat([df_economic_income_1, df_economic_income_2, df_economic_income_3, df_economic_income_4, df_economic_income_5, df_economic_income_6], ignore_index=True)\n",
    "df_economic_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>anio</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>2015</td>\n",
       "      <td>POINT (-71.51186 -16.36774)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>2015</td>\n",
       "      <td>POINT (-71.50151 -16.37566)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>2015</td>\n",
       "      <td>POINT (-71.50128 -16.39534)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>2015</td>\n",
       "      <td>POINT (-71.52681 -16.41053)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>2015</td>\n",
       "      <td>POINT (-71.51339 -16.40597)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  anio                     geometry\n",
       "0   53  2015  POINT (-71.51186 -16.36774)\n",
       "1   73  2015  POINT (-71.50151 -16.37566)\n",
       "2   92  2015  POINT (-71.50128 -16.39534)\n",
       "3  101  2015  POINT (-71.52681 -16.41053)\n",
       "4  103  2015  POINT (-71.51339 -16.40597)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RABIA\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta a la carpeta con archivos KML\n",
    "folder_path = \"/home/pantro/Descargas/KML_casos_rabia/\"\n",
    "kml_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".kml\")])\n",
    "\n",
    "# Namespace usado en KML\n",
    "ns = {\"kml\": \"http://www.opengis.net/kml/2.2\"}\n",
    "\n",
    "features = []\n",
    "\n",
    "for filename in kml_files:\n",
    "    filepath = os.path.join(folder_path, filename)\n",
    "    try:\n",
    "        year = int(filename.replace(\".kml\", \"\"))\n",
    "    except ValueError:\n",
    "        continue  # omite archivos mal nombrados\n",
    "\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    placemarks = root.findall(\".//kml:Placemark\", ns)\n",
    "    for pm in placemarks:\n",
    "        coord_tag = pm.find(\".//kml:coordinates\", ns)\n",
    "        name_tag = pm.find(\"kml:name\", ns)\n",
    "        if coord_tag is not None:\n",
    "            coords_text = coord_tag.text.strip()\n",
    "            try:\n",
    "                lon, lat, *_ = map(float, coords_text.split(','))\n",
    "                name = name_tag.text.strip() if name_tag is not None else None\n",
    "                features.append({\n",
    "                    \"name\": name,\n",
    "                    \"anio\": year,\n",
    "                    \"geometry\": Point(lon, lat),\n",
    "                })\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "# Crear GeoDataFrame\n",
    "gdf_rabies = gpd.GeoDataFrame(features, crs=\"EPSG:4326\")\n",
    "\n",
    "# Mostrar\n",
    "print(gdf_rabies.shape)\n",
    "gdf_rabies.head()\n",
    "\n",
    "# Si quieres guardar como GeoJSON\n",
    "# gdf.to_file(\"casos_rabia_completo.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprosesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_zamacola_graph.py\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from geopy.distance import geodesic\n",
    "from shapely.geometry import Point, Polygon, LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4296, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128035/2957687187.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cuadra_polys = df_economic_income_clean.groupby(\"ident\").apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuadra_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>ingreso_economico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4.100-1</td>\n",
       "      <td>POLYGON ((-71.58095 -16.35108, -71.58178 -16.3...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4.100-10</td>\n",
       "      <td>POLYGON ((-71.58352 -16.34361, -71.58349 -16.3...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4.100-11</td>\n",
       "      <td>POLYGON ((-71.58344 -16.34353, -71.58179 -16.3...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.4.100-12</td>\n",
       "      <td>POLYGON ((-71.58582 -16.34319, -71.58592 -16.3...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4.100-2</td>\n",
       "      <td>POLYGON ((-71.58400 -16.34949, -71.58416 -16.3...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cuadra_id                                           geometry  \\\n",
       "0   1.4.100-1  POLYGON ((-71.58095 -16.35108, -71.58178 -16.3...   \n",
       "1  1.4.100-10  POLYGON ((-71.58352 -16.34361, -71.58349 -16.3...   \n",
       "2  1.4.100-11  POLYGON ((-71.58344 -16.34353, -71.58179 -16.3...   \n",
       "3  1.4.100-12  POLYGON ((-71.58582 -16.34319, -71.58592 -16.3...   \n",
       "4   1.4.100-2  POLYGON ((-71.58400 -16.34949, -71.58416 -16.3...   \n",
       "\n",
       "  ingreso_economico  \n",
       "0                 D  \n",
       "1                 D  \n",
       "2                 D  \n",
       "3                 D  \n",
       "4                 D  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NIVEL SOCIECONOMICO\n",
    "# Eliminar filas vacías (sin coordenadas)\n",
    "df_economic_income_clean = df_economic_income[\n",
    "    (df_economic_income[\"lat\"].str.strip() != '') &\n",
    "    (df_economic_income[\"long\"].str.strip() != '')\n",
    "].copy()\n",
    "\n",
    "# Agrupar por 'ident' (ID de cuadra) y construir polígonos\n",
    "cuadra_polys = df_economic_income_clean.groupby(\"ident\").apply(\n",
    "    lambda g: pd.Series({\n",
    "        \"geometry\": Polygon(zip(g[\"long\"], g[\"lat\"])),\n",
    "        \"ingreso_economico\": g[\"ingreso_economico\"].unique()[0]  # único valor\n",
    "    })\n",
    ").reset_index()\n",
    "cuadra_polys.columns = [\"cuadra_id\", \"geometry\", \"ingreso_economico\"]\n",
    "\n",
    "# Crear GeoDataFrame con polígonos\n",
    "gdf_economic_income = gpd.GeoDataFrame(cuadra_polys, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "print(gdf_economic_income.shape)\n",
    "gdf_economic_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>C.S. MARITZA CAMPO DIAZ</td>\n",
       "      <td>-16.351375</td>\n",
       "      <td>-71.562525</td>\n",
       "      <td>POINT (-71.56252 -16.35137)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>P.S. CIUDAD MUNICIPAL</td>\n",
       "      <td>-16.325474</td>\n",
       "      <td>-71.594062</td>\n",
       "      <td>POINT (-71.59406 -16.32547)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>P.S. PERUARBO</td>\n",
       "      <td>-16.345310</td>\n",
       "      <td>-71.600061</td>\n",
       "      <td>POINT (-71.60006 -16.34531)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>P.S. NAZARENO</td>\n",
       "      <td>-16.328171</td>\n",
       "      <td>-71.549513</td>\n",
       "      <td>POINT (-71.54951 -16.32817)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C.S. FRANCISCO BOLOGNESI</td>\n",
       "      <td>-16.354767</td>\n",
       "      <td>-71.542092</td>\n",
       "      <td>POINT (-71.54209 -16.35477)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                      name        lat       long  \\\n",
       "0       22   C.S. MARITZA CAMPO DIAZ -16.351375 -71.562525   \n",
       "1       26     P.S. CIUDAD MUNICIPAL -16.325474 -71.594062   \n",
       "2       22             P.S. PERUARBO -16.345310 -71.600061   \n",
       "3       24             P.S. NAZARENO -16.328171 -71.549513   \n",
       "4        5  C.S. FRANCISCO BOLOGNESI -16.354767 -71.542092   \n",
       "\n",
       "                      geometry  \n",
       "0  POINT (-71.56252 -16.35137)  \n",
       "1  POINT (-71.59406 -16.32547)  \n",
       "2  POINT (-71.60006 -16.34531)  \n",
       "3  POINT (-71.54951 -16.32817)  \n",
       "4  POINT (-71.54209 -16.35477)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PUESTOS DE SALUD\n",
    "# Suponiendo que df_health_posts tiene columnas 'lat' y 'long'\n",
    "gdf_health_posts = gpd.GeoDataFrame(\n",
    "    df_health_posts,\n",
    "    geometry=gpd.points_from_xy(df_health_posts['long'], df_health_posts['lat']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "# Filtrar filas: asegurarse que 'cluster' sea un número (ignorar NaNs o strings)\n",
    "gdf_health_posts = gdf_health_posts[pd.to_numeric(gdf_health_posts['cluster'], errors='coerce').notnull()]\n",
    "\n",
    "# Convertir 'cluster' a numérico si aún no lo es\n",
    "gdf_health_posts['cluster'] = gdf_health_posts['cluster'].astype(int)\n",
    "\n",
    "# Seleccionar solo las columnas deseadas\n",
    "gdf_health_posts = gdf_health_posts[['cluster', 'name', 'lat', 'long', 'geometry']]\n",
    "print(gdf_health_posts.shape)\n",
    "gdf_health_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_128035/627060655.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: LineString(zip(group[\"long\"], group[\"lat\"])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r_prin_001</td>\n",
       "      <td>LINESTRING (-71.48611 -16.30382, -71.48621 -16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r_prin_002</td>\n",
       "      <td>LINESTRING (-71.43686 -16.42426, -71.43687 -16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r_prin_003</td>\n",
       "      <td>LINESTRING (-71.41278 -16.57048, -71.41280 -16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r_prin_004</td>\n",
       "      <td>LINESTRING (-71.43694 -16.49497, -71.43696 -16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>torr_001</td>\n",
       "      <td>LINESTRING (-71.46112 -16.36777, -71.46113 -16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ident                                           geometry\n",
       "0  r_prin_001  LINESTRING (-71.48611 -16.30382, -71.48621 -16...\n",
       "1  r_prin_002  LINESTRING (-71.43686 -16.42426, -71.43687 -16...\n",
       "2  r_prin_003  LINESTRING (-71.41278 -16.57048, -71.41280 -16...\n",
       "3  r_prin_004  LINESTRING (-71.43694 -16.49497, -71.43696 -16...\n",
       "4    torr_001  LINESTRING (-71.46112 -16.36777, -71.46113 -16..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TORRENTERAS\n",
    "# Eliminar filas vacías (sin coordenadas)\n",
    "df_water_channels_clean = df_water_channels[\n",
    "    (df_water_channels[\"lat\"].str.strip() != '') &\n",
    "    (df_water_channels[\"long\"].str.strip() != '')\n",
    "]\n",
    "# Crear geometrías LineString por grupo\n",
    "lineas = (\n",
    "    df_water_channels_clean.groupby(\"ident\")\n",
    "    .apply(lambda group: LineString(zip(group[\"long\"], group[\"lat\"])))\n",
    "    .reset_index(name=\"geometry\")\n",
    ")\n",
    "\n",
    "# Convertir a GeoDataFrame\n",
    "gdf_water_channels = gpd.GeoDataFrame(lineas, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "print(gdf_water_channels.shape)\n",
    "gdf_water_channels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solo los puestos de salud y los casos de rabia que estan dentro del cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86760/412664487.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cluster_clean[\"lat\"] = df_cluster_clean[\"lat\"].astype(float)\n",
      "/tmp/ipykernel_86760/412664487.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cluster_clean[\"long\"] = df_cluster_clean[\"long\"].astype(float)\n",
      "/tmp/ipykernel_86760/412664487.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cluster_polys = df_cluster_clean.groupby(\"ident\").apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ident                                           geometry\n",
      "0  ZAMACOLA_01  POLYGON ((-71.54220 -16.32096, -71.54209 -16.3...\n",
      "1  ZAMACOLA_02  POLYGON ((-71.56913 -16.32129, -71.56928 -16.3...\n",
      "2  ZAMACOLA_03  POLYGON ((-71.57338 -16.32124, -71.57415 -16.3...\n",
      "3  ZAMACOLA_04  POLYGON ((-71.60649 -16.32654, -71.60492 -16.3...\n",
      "4  ZAMACOLA_05  POLYGON ((-71.61663 -16.32034, -71.61677 -16.3...\n",
      "---------------------------------------\n",
      "(4, 7)\n",
      "   cluster                     name        lat       long  \\\n",
      "0       22  C.S. MARITZA CAMPO DIAZ -16.351375 -71.562525   \n",
      "1       26    P.S. CIUDAD MUNICIPAL -16.325474 -71.594062   \n",
      "2       22            P.S. PERUARBO -16.345310 -71.600061   \n",
      "3       24            P.S. NAZARENO -16.328171 -71.549513   \n",
      "\n",
      "                      geometry  index_right        ident  \n",
      "0  POINT (-71.56252 -16.35137)            5  ZAMACOLA_06  \n",
      "1  POINT (-71.59406 -16.32547)            3  ZAMACOLA_04  \n",
      "2  POINT (-71.60006 -16.34531)            5  ZAMACOLA_06  \n",
      "3  POINT (-71.54951 -16.32817)            1  ZAMACOLA_02  \n",
      "---------------------------------------\n",
      "(161, 5)\n",
      "   name  anio                     geometry  index_right        ident\n",
      "19  576  2016  POINT (-71.55067 -16.31381)            0  ZAMACOLA_01\n",
      "21  574  2016  POINT (-71.53193 -16.29507)            0  ZAMACOLA_01\n",
      "23  567  2016  POINT (-71.56201 -16.34734)            5  ZAMACOLA_06\n",
      "24  566  2016  POINT (-71.54886 -16.30677)            0  ZAMACOLA_01\n",
      "25  563  2016  POINT (-71.58124 -16.33749)            1  ZAMACOLA_02\n"
     ]
    }
   ],
   "source": [
    "# Filtrar puestos de salud y casos de rabia solo para el cluster 27\n",
    "df_cluster_1 = pd.read_csv(\"/home/pantro/Descargas/SPATIAL_DATA_AQP/Clusters_AQP/Limites_Cluster_22_09may2025.csv\", sep=\";\")\n",
    "df_cluster_2 = pd.read_csv(\"/home/pantro/Descargas/SPATIAL_DATA_AQP/Clusters_AQP/Limites_Cluster_23_09may2025.csv\", sep=\";\")\n",
    "df_cluster_3 = pd.read_csv(\"/home/pantro/Descargas/SPATIAL_DATA_AQP/Clusters_AQP/Limites_Cluster_24_09may2025.csv\", sep=\";\")\n",
    "df_cluster_4 = pd.read_csv(\"/home/pantro/Descargas/SPATIAL_DATA_AQP/Clusters_AQP/Limites_Cluster_25_09may2025.csv\", sep=\";\")\n",
    "df_cluster_5 = pd.read_csv(\"/home/pantro/Descargas/SPATIAL_DATA_AQP/Clusters_AQP/Limites_Cluster_26_09may2025.csv\", sep=\";\")\n",
    "df_cluster_6 = pd.read_csv(\"/home/pantro/Descargas/SPATIAL_DATA_AQP/Clusters_AQP/Limites_Cluster_27_09may2025.csv\", sep=\";\")\n",
    "# Unir los DataFrames\n",
    "df_cluster = pd.concat([df_cluster_1, df_cluster_2, df_cluster_3, df_cluster_4, df_cluster_5, df_cluster_6], ignore_index=True)\n",
    "# 1. Eliminar filas sin coordenadas (NaN o vacías)\n",
    "df_cluster_clean = df_cluster[\n",
    "    (df_cluster[\"lat\"].str.strip() != '') &\n",
    "    (df_cluster[\"long\"].str.strip() != '')\n",
    "]\n",
    "\n",
    "# 2. Asegurar que las coordenadas sean float\n",
    "df_cluster_clean[\"lat\"] = df_cluster_clean[\"lat\"].astype(float)\n",
    "df_cluster_clean[\"long\"] = df_cluster_clean[\"long\"].astype(float)\n",
    "\n",
    "# 3. Agrupar por 'ident' y construir polígonos\n",
    "cluster_polys = df_cluster_clean.groupby(\"ident\").apply(\n",
    "    lambda g: Polygon(zip(g[\"long\"], g[\"lat\"]))\n",
    ").reset_index(name=\"geometry\")\n",
    "\n",
    "# 4. Crear GeoDataFrame\n",
    "gdf_cluster = gpd.GeoDataFrame(cluster_polys, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "print(gdf_cluster.head())\n",
    "\n",
    "# OBTENER SOLO LOS PUESTOS DE SALUD DENTRO DEL CLUSTER\n",
    "gdf_health_posts = gpd.sjoin(\n",
    "    gdf_health_posts,\n",
    "    gdf_cluster,\n",
    "    how=\"inner\",\n",
    "    predicate=\"intersects\"\n",
    ")\n",
    "print(\"---------------------------------------\")\n",
    "print(gdf_health_posts.shape)\n",
    "print(gdf_health_posts.head())\n",
    "\n",
    "print(\"=======================================================\")\n",
    "# OBTENER SOLO LOS CASOS DE RABIA DENTRO DEL CLUSTER\n",
    "gdf_rabies = gpd.sjoin(\n",
    "    gdf_rabies,\n",
    "    gdf_cluster,\n",
    "    how=\"inner\",\n",
    "    predicate=\"intersects\"\n",
    ")\n",
    "print(\"---------------------------------------\")\n",
    "print(gdf_rabies.shape)\n",
    "print(gdf_rabies.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import FeatureGroup, LayerControl, Marker, PolyLine, GeoJson\n",
    "import geopandas as gpd\n",
    "\n",
    "# Mapa base centrado en Arequipa\n",
    "m = folium.Map(location=[-16.3989, -71.5350], zoom_start=12)\n",
    "\n",
    "# === CAPA 1: Casos de RABIA (Points) ===\n",
    "fg_rabies = FeatureGroup(name=\"Casos de Rabia\")\n",
    "for _, row in gdf_rabies.iterrows():\n",
    "    Marker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        popup=\"Caso de rabia\",\n",
    "        icon=folium.Icon(color=\"red\", icon=\"exclamation-sign\")\n",
    "    ).add_to(fg_rabies)\n",
    "fg_rabies.add_to(m)\n",
    "\n",
    "# === CAPA 2: Nivel Socioeconómico (Polygons) ===\n",
    "fg_income = FeatureGroup(name=\"Nivel Socioeconómico\")\n",
    "GeoJson(\n",
    "    gdf_economic_income,\n",
    "    name=\"Nivel Socioeconómico\",\n",
    "    style_function=lambda x: {\n",
    "        'fillColor': '#00b894',\n",
    "        'color': '#2d3436',\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.4,\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"cuadra_id\"])\n",
    ").add_to(fg_income)\n",
    "fg_income.add_to(m)\n",
    "\n",
    "# === CAPA 3: Puestos de Salud (Points) ===\n",
    "fg_salud = FeatureGroup(name=\"Puestos de Salud\")\n",
    "for _, row in gdf_health_posts.iterrows():\n",
    "    Marker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        popup=row[\"name\"],\n",
    "        icon=folium.Icon(color=\"blue\", icon=\"plus-sign\")\n",
    "    ).add_to(fg_salud)\n",
    "fg_salud.add_to(m)\n",
    "\n",
    "# === CAPA 4: Torrenteras (LineStrings) ===\n",
    "fg_torrenteras = FeatureGroup(name=\"Torrenteras\")\n",
    "GeoJson(\n",
    "    gdf_water_channels,\n",
    "    name=\"Torrenteras\",\n",
    "    style_function=lambda x: {\n",
    "        'color': '#6c5ce7',\n",
    "        'weight': 2,\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"ident\"])\n",
    ").add_to(fg_torrenteras)\n",
    "fg_torrenteras.add_to(m)\n",
    "\n",
    "# === CAPA 5: Clústeres (Polygons) ===\n",
    "fg_cluster = FeatureGroup(name=\"Clústeres\")\n",
    "GeoJson(\n",
    "    gdf_cluster,\n",
    "    name=\"Clústeres\",\n",
    "    style_function=lambda x: {\n",
    "        'fillColor': '#ffeaa7',\n",
    "        'color': '#d35400',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0.3,\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"ident\"])\n",
    ").add_to(fg_cluster)\n",
    "fg_cluster.add_to(m)\n",
    "\n",
    "# === Control de capas ===\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# === Guardar o mostrar ===\n",
    "m.save(\"mapa_solo_objetivo_fase2.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros 2016-2021:  145\n",
      "anio\n",
      "2021    44\n",
      "2016    32\n",
      "2018    23\n",
      "2017    22\n",
      "2019    17\n",
      "2020     7\n",
      "Name: count, dtype: int64\n",
      "Cantidad de registros 2022-2024:  16\n",
      "anio\n",
      "2022    11\n",
      "2023     3\n",
      "2024     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#- SEPARAR CASOS DE RABIA DEL 2015-2021 PARA TRAIN_VAL Y 2022-2024 PARA TEST\n",
    "gdf_rabies_train_val = gdf_rabies[(gdf_rabies[\"anio\"] > 2015) & (gdf_rabies[\"anio\"] < 2022)]\n",
    "gdf_rabies_test = gdf_rabies[(gdf_rabies[\"anio\"] > 2021)]\n",
    "print(\"Cantidad de registros 2016-2021: \",len(gdf_rabies_train_val))\n",
    "print(gdf_rabies_train_val[\"anio\"].value_counts())\n",
    "print(\"Cantidad de registros 2022-2024: \",len(gdf_rabies_test))\n",
    "print(gdf_rabies_test[\"anio\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar el grafo para TRAIN_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de cuadras afectadas: 13\n"
     ]
    }
   ],
   "source": [
    "# build_zamacola_graph.py (versión con parámetros configurables y visualización)\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from shapely.geometry import Point\n",
    "from geopy.distance import geodesic\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# TEST  # TRAIN_VAL\n",
    "gdf_rabies = gdf_rabies_test.copy()#gdf_rabies_train_val.copy()\n",
    "\n",
    "# Cambiar a \"EPSG:32719\"\n",
    "gdf_rabies_proj = gdf_rabies.to_crs(\"EPSG:32719\")\n",
    "gdf_economic_income_proj = gdf_economic_income.to_crs(\"EPSG:32719\")\n",
    "gdf_health_posts_proj = gdf_health_posts.to_crs(\"EPSG:32719\")\n",
    "gdf_water_channels_proj = gdf_water_channels.to_crs(\"EPSG:32719\")\n",
    "\n",
    "# ---------------------------\n",
    "# PARÁMETROS CONFIGURABLES\n",
    "# ---------------------------\n",
    "CUADRA_NEIGHBOR_RADIUS = 200  # metros para definir vecindad entre cuadras\n",
    "CUADRA_TORRENTERA_DIST = 500  # metros\n",
    "CUADRA_PROXIMITY_RABIES_CASE_RADIUS = 100  # metros. Se busca a las cuadras que esten dentro de 100 metros para decir que todas ellas tienen rabia\n",
    "\n",
    "# ---------------------------\n",
    "# CARGA DE DATOS (GeoDataFrames preprocesados):\n",
    "# gdf_economic_income: cuadras como POLYGON\n",
    "# gdf_health_posts: centros de salud como POINT\n",
    "# gdf_water_channels: torrenteras como LINESTRING\n",
    "# gdf_rabies: casos de rabia como POINT + año\n",
    "# ---------------------------\n",
    "\n",
    "# Asegurar proyección métrica\n",
    "cuadras = gdf_economic_income_proj.copy()\n",
    "rabies = gdf_rabies_proj.copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Calcular centroide + coordenadas\n",
    "# -----------------------------\n",
    "cuadras[\"centroid\"] = cuadras.geometry.centroid\n",
    "cuadras[\"lat\"] = cuadras.centroid.y\n",
    "cuadras[\"long\"] = cuadras.centroid.x\n",
    "\n",
    "# -----------------------------\n",
    "# One-hot encoding ingreso económico\n",
    "# -----------------------------\n",
    "cuadras = pd.get_dummies(cuadras, columns=[\"ingreso_economico\"], prefix=\"ingreso\")\n",
    "\n",
    "# -----------------------------\n",
    "# Casos de rabia dentro de la cuadra\n",
    "# -----------------------------\n",
    "cuadras[\"num_rabies_cases_in_cuadra\"] = cuadras.geometry.apply(\n",
    "    lambda poly: rabies[rabies.within(poly)].shape[0]\n",
    ")\n",
    "# Contar cantidad de cuadras con al menos un caso de rabia\n",
    "num_cuadras_afectadas = (cuadras[\"num_rabies_cases_in_cuadra\"] > 0).sum()\n",
    "print(f\"Cantidad de cuadras afectadas: {num_cuadras_afectadas}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Distancia al caso de rabia más cercano en 100 m\n",
    "# -----------------------------\n",
    "def min_dist_to_case(poly_centroid, rabies_points, max_dist):\n",
    "    distances = rabies_points.distance(poly_centroid)\n",
    "    close = distances[distances <= max_dist]\n",
    "    return close.min() if not close.empty else np.nan\n",
    "\n",
    "cuadras[\"min_dist_to_rabies_case\"] = cuadras[\"centroid\"].apply(\n",
    "    lambda p: min_dist_to_case(p, rabies.geometry, CUADRA_PROXIMITY_RABIES_CASE_RADIUS)\n",
    ")\n",
    "# Rellenar NaN con un valor alto para que redes neuronales lo manejen mejor\n",
    "cuadras[\"min_dist_to_rabies_case\"] = cuadras[\"min_dist_to_rabies_case\"].fillna(9999)\n",
    "\n",
    "# -----------------------------\n",
    "# Selección de columnas de features\n",
    "# -----------------------------\n",
    "feature_columns = (\n",
    "    [\"lat\", \"long\", \"num_rabies_cases_in_cuadra\", \"min_dist_to_rabies_case\"]\n",
    "    #[\"lat\", \"long\", \"min_dist_to_rabies_case\"] # Teste para la fase2_1\n",
    "    + [c for c in cuadras.columns if c.startswith(\"ingreso_\")]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Normalizar features\n",
    "# -----------------------------\n",
    "scaler = MinMaxScaler()\n",
    "cuadra_features = scaler.fit_transform(cuadras[feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuadra_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>centroid</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ingreso_B</th>\n",
       "      <th>ingreso_C</th>\n",
       "      <th>ingreso_D</th>\n",
       "      <th>ingreso_E</th>\n",
       "      <th>num_rabies_cases_in_cuadra</th>\n",
       "      <th>min_dist_to_rabies_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [cuadra_id, geometry, centroid, lat, long, ingreso_B, ingreso_C, ingreso_D, ingreso_E, num_rabies_cases_in_cuadra, min_dist_to_rabies_case]\n",
       "Index: []"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cuadras_filtradas = cuadras[cuadras[\"num_rabies_cases_in_cuadra\"] > 1]\n",
    "#cuadras_filtradas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivos (1): 13\n",
      "Negativos (0): 4283\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# CREAR GRAFO HETEROGÉNEO\n",
    "# ---------------------------\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "# Cuadras como nodos\n",
    "data[\"cuadra\"].x = torch.tensor(cuadra_features, dtype=torch.float)\n",
    "data['cuadra'].feature_columns = feature_columns\n",
    "data[\"cuadra\"].cuadra_id = cuadras[\"cuadra_id\"].tolist()\n",
    "data[\"cuadra\"].node_index = cuadras.index.to_list()  # <-- Aquí guardar índices reales\n",
    "\n",
    "## OJO: Solo por esta vez, porque esto debe de manipularse en el modelo\n",
    "# Crear y guardar etiquetas binarias directamente\n",
    "#col_idx = feature_columns.index(\"num_rabies_cases_in_cuadra\")\n",
    "#num_cases_tensor = data['cuadra'].x[:, col_idx]\n",
    "#data['cuadra'].y = (num_cases_tensor > 0).long()\n",
    "data['cuadra'].y = torch.tensor(\n",
    "    (cuadras[\"num_rabies_cases_in_cuadra\"] > 0).astype(int).values,\n",
    "    dtype=torch.long\n",
    ")\n",
    "num_pos = torch.sum(data['cuadra'].y).item()\n",
    "num_total = data['cuadra'].y.size(0)\n",
    "num_neg = num_total - num_pos\n",
    "print(f\"Positivos (1): {num_pos}\")\n",
    "print(f\"Negativos (0): {num_neg}\")\n",
    "\n",
    "# Puestos de salud como nodos\n",
    "health_posts = gdf_health_posts_proj.copy()\n",
    "data[\"health_post\"].x = torch.tensor(health_posts[[\"lat\", \"long\"]].values, dtype=torch.float)\n",
    "data[\"health_post\"].name = health_posts[\"name\"].tolist()\n",
    "data[\"health_post\"].node_index = health_posts.index.to_list()  # <-- guardar índices también\n",
    "\n",
    "# Torrenteras como nodos\n",
    "torrenteras = gdf_water_channels_proj.copy()\n",
    "torrenteras[\"lat\"] = torrenteras.geometry.centroid.y\n",
    "torrenteras[\"long\"] = torrenteras.geometry.centroid.x\n",
    "data[\"water_channel\"].x = torch.tensor(torrenteras[[\"lat\", \"long\"]].values, dtype=torch.float)\n",
    "data[\"water_channel\"].ident = torrenteras[\"ident\"].tolist()\n",
    "data[\"water_channel\"].node_index = torrenteras.index.to_list()  # <-- guardar índices\n",
    "\n",
    "# 🦠 Casos de rabia como nodos con año + punto geográfico\n",
    "#gdf_rabies_proj = gdf_rabies_proj.reset_index(drop=True)\n",
    "#gdf_rabies_proj[\"lat\"] = gdf_rabies_proj.geometry.y\n",
    "#gdf_rabies_proj[\"long\"] = gdf_rabies_proj.geometry.x\n",
    "#data[\"rabies_case\"].x = torch.tensor(gdf_rabies_proj[[\"lat\", \"long\"]].values, dtype=torch.float)\n",
    "#data[\"rabies_case\"].name = gdf_rabies_proj[\"name\"].tolist()\n",
    "#data[\"rabies_case\"].year = torch.tensor(gdf_rabies_proj[\"anio\"].values, dtype=torch.long)\n",
    "#data[\"rabies_case\"].node_index = gdf_rabies_proj.index.to_list()  # <-- guardar índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "*****************  df_preview_cuadra  *************************\n",
      "------------------------------------------------------------------\n",
      "    cuadra_id  node_index       lat      long\n",
      "0   1.4.100-1           0  0.343036  0.524072\n",
      "1  1.4.100-10           1  0.401710  0.511256\n",
      "2  1.4.100-11           2  0.406504  0.519437\n",
      "3  1.4.100-12           3  0.405803  0.493044\n",
      "4   1.4.100-2           4  0.341268  0.507758\n",
      "------------------------------------------------------------------\n",
      "*****************  df_preview_health_post  *************************\n",
      "------------------------------------------------------------------\n",
      "                      name  node_index        lat       long\n",
      "0  C.S. MARITZA CAMPO DIAZ           0 -16.351376 -71.562523\n",
      "1    P.S. CIUDAD MUNICIPAL           1 -16.325474 -71.594063\n",
      "2            P.S. PERUARBO           2 -16.345310 -71.600060\n",
      "3            P.S. NAZARENO           3 -16.328171 -71.549515\n"
     ]
    }
   ],
   "source": [
    "# COMPROBACION DE DATOS\n",
    "## PARA PROPOSITOS DE VISUALIZACION Y VER QUE TODO VAYA BIEN\n",
    "#\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"*****************  df_preview_cuadra  *************************\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "df_preview_cuadra = pd.DataFrame({\n",
    "    \"cuadra_id\": data[\"cuadra\"].cuadra_id[:5],\n",
    "    \"node_index\": data[\"cuadra\"].node_index[:5],\n",
    "    \"lat\": data[\"cuadra\"].x[:5, 0].tolist(),\n",
    "    \"long\": data[\"cuadra\"].x[:5, 1].tolist()\n",
    "})\n",
    "\n",
    "print(df_preview_cuadra)\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"*****************  df_preview_health_post  *************************\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "df_preview_health_post = pd.DataFrame({\n",
    "    \"name\": data[\"health_post\"].name[:5],\n",
    "    \"node_index\": data[\"health_post\"].node_index[:5],\n",
    "    \"lat\": data[\"health_post\"].x[:5, 0].tolist(),\n",
    "    \"long\": data[\"health_post\"].x[:5, 1].tolist()\n",
    "})\n",
    "\n",
    "print(df_preview_health_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# RELACIONES (ARISTAS)\n",
    "# ---------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# Cuadra ↔ Cuadra (vecinas por distancia entre centroides)\n",
    "# ---------------------------\n",
    "# Conectamos centroides de cuadras si están a menos de CUADRA_NEIGHBOR_RADIUS (100m)\n",
    "\n",
    "# Extraer coordenadas de los centroides\n",
    "cuadra_coords = cuadras[[\"cuadra_id\", \"long\", \"lat\"]].values\n",
    "\n",
    "# Generar relaciones de vecindad\n",
    "edges_src, edges_dst = [], []\n",
    "for i in range(len(cuadra_coords)):\n",
    "    for j in range(i + 1, len(cuadra_coords)):\n",
    "        _, x1, y1 = cuadra_coords[i]\n",
    "        _, x2, y2 = cuadra_coords[j]\n",
    "        dist = ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5  # Distancia euclidiana\n",
    "        if dist < CUADRA_NEIGHBOR_RADIUS:\n",
    "            edges_src.append(i)\n",
    "            edges_dst.append(j)\n",
    "\n",
    "# Hacer grafo no dirigido (duplicar aristas en sentido contrario)\n",
    "edges_src += edges_dst\n",
    "edges_dst += edges_src[:len(edges_dst)]\n",
    "\n",
    "# Convertir a tensor de aristas\n",
    "if edges_src:\n",
    "    data[\"cuadra\", \"vecina_de\", \"cuadra\"].edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Cuadra → Puesto de salud más cercano y pone la distancia como atributo\n",
    "# ---------------------------\n",
    "# Asegurar que las coordenadas estén listas\n",
    "cuadras[\"x\"] = cuadras[\"centroid\"].x\n",
    "cuadras[\"y\"] = cuadras[\"centroid\"].y\n",
    "\n",
    "health_posts[\"x\"] = health_posts.geometry.x\n",
    "health_posts[\"y\"] = health_posts.geometry.y\n",
    "\n",
    "# Crear relaciones\n",
    "edges_cuadra_ps = []\n",
    "distancias = []\n",
    "\n",
    "for i, cuadra in cuadras.iterrows():\n",
    "    dists = health_posts.apply(\n",
    "        lambda row: ((cuadra.x - row.x) ** 2 + (cuadra.y - row.y) ** 2) ** 0.5, axis=1\n",
    "    )\n",
    "    closest = dists.idxmin()\n",
    "    distance = dists[closest]\n",
    "    edges_cuadra_ps.append((i, closest))\n",
    "    distancias.append(distance)\n",
    "\n",
    "# Crear edge_index\n",
    "src, dst = zip(*edges_cuadra_ps)\n",
    "data[\"cuadra\", \"reporta_a\", \"health_post\"].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "# Normalizar distancias\n",
    "scaler = MinMaxScaler()\n",
    "edge_attr_np = scaler.fit_transform(torch.tensor(distancias, dtype=torch.float).reshape(-1, 1))\n",
    "edge_attr = torch.tensor(edge_attr_np, dtype=torch.float)\n",
    "\n",
    "# Asignar atributo (relación original)\n",
    "data[\"cuadra\", \"reporta_a\", \"health_post\"].edge_attr = edge_attr\n",
    "\n",
    "# 🔁 Agregar relación inversa: health_post → cuadra\n",
    "data[\"health_post\", \"atiende_a\", \"cuadra\"].edge_index = torch.tensor([dst, src], dtype=torch.long)\n",
    "data[\"health_post\", \"atiende_a\", \"cuadra\"].edge_attr = edge_attr  # o edge_attr.clone() si vas a modificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Cuadra → Torrenteras (con distancia como atributo)\n",
    "# ---------------------------\n",
    "edges_cuadra_torr = []\n",
    "distancias_torr = []\n",
    "\n",
    "for i, cuadra in cuadras.iterrows():\n",
    "    for j, torr in torrenteras.iterrows():\n",
    "        dist = cuadra.geometry.distance(torr.geometry)  # distancia mas corta entre los elemento en metros\n",
    "        if dist < CUADRA_TORRENTERA_DIST:\n",
    "            edges_cuadra_torr.append((i, j))\n",
    "            distancias_torr.append(dist)\n",
    "\n",
    "if edges_cuadra_torr:\n",
    "    src, dst = zip(*edges_cuadra_torr)\n",
    "    data[\"cuadra\", \"cerca_de\", \"water_channel\"].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "    # Normalizar y añadir edge_attr\n",
    "    scaler = MinMaxScaler()\n",
    "    edge_attr_torr = scaler.fit_transform(torch.tensor(distancias_torr).reshape(-1, 1))\n",
    "    data[\"cuadra\", \"cerca_de\", \"water_channel\"].edge_attr = torch.tensor(edge_attr_torr, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# ---------------------------\\n# 🦠 Caso de rabia → Cuadra (sjoin espacial)\\n# ---------------------------\\n\\n# Eliminar columnas conflictivas si existen\\ngdf_rabies_proj = gdf_rabies_proj.drop(columns=[\"index_left\", \"index_right\"], errors=\"ignore\")\\ncuadras = cuadras.drop(columns=[\"index_left\", \"index_right\"], errors=\"ignore\")\\n\\n# Reparar geometrías inválidas\\ncuadras[\"geometry\"] = cuadras[\"geometry\"].buffer(0)\\n\\n# Unificar CRS\\ngdf_rabies_proj = gdf_rabies_proj.to_crs(cuadras.crs)\\n\\n# Spatial join (casos de rabia dentro de alguna cuadra)\\njoined = gpd.sjoin(gdf_rabies_proj, cuadras, how=\"left\", predicate=\"intersects\")\\n\\n# Mapeos de índice original a índice relativo\\nrabies_id_to_rel = {nid: i for i, nid in enumerate(data[\"rabies_case\"].node_index)}\\ncuadra_id_to_rel = {nid: i for i, nid in enumerate(data[\"cuadra\"].node_index)}\\n\\n# Aristas caso de rabia → cuadra\\nedges_rabia_cuadra = [] # Casos de rabia dentros de la cuadra\\nedges_riesgo_proximidad = [] # Casos de rabia fuera de las cuadras\\n# Arista cuadra -> caso de rabia\\nedges_cercano_a_caso = []\\n\\n# |= Casos que cayeron dentro de una cuadra\\nfor _, row in joined.dropna(subset=[\"index_right\"]).iterrows():\\n    src_orig = row.name\\n    dst_orig = int(row[\"index_right\"])\\n    if src_orig in rabies_id_to_rel and dst_orig in cuadra_id_to_rel:\\n        src = rabies_id_to_rel[src_orig]\\n        dst = cuadra_id_to_rel[dst_orig]\\n        edges_rabia_cuadra.append((src, dst))\\n\\n# Construyendo la relacion\\nif edges_rabia_cuadra:\\n    src, dst = zip(*edges_rabia_cuadra)\\n    data[\"rabies_case\", \"ocurre_en\", \"cuadra\"].edge_index = torch.tensor([src, dst], dtype=torch.long)# Convertir a tensor de aristas\\n# Crear aristas inversas\\nedge_index_ocurre_en = data[\"rabies_case\", \"ocurre_en\", \"cuadra\"].edge_index\\ndata[\"cuadra\", \"tiene_caso\", \"rabies_case\"].edge_index = edge_index_ocurre_en.flip(0)\\n\\n\\n# |= Propagacion de los casos de rabia a las cuadras dentro del radio de RABIES_CASE_WITHOUT_CUADRA (100m)\\nno_match = joined.copy()\\ncuadras_afectadas = set()\\ncasos_dentro_cuadra = joined[\"index_right\"].notna().sum()\\ncasos_fuera_cuadra = joined[\"index_right\"].isna().sum()\\n\\nfor _, row in no_match.iterrows():\\n    src_orig = row.name\\n    caso_point = row.geometry\\n    dists = cuadras.geometry.distance(caso_point)\\n    \\n    # Filtrar las cuadras dentro del rango definido\\n    cuadras_cercanas = dists[dists <= RABIES_CASE_PROXIMITY_CUADRA]\\n\\n    for dst_orig in cuadras_cercanas.index:\\n        if src_orig in rabies_id_to_rel and dst_orig in cuadra_id_to_rel:\\n            src = rabies_id_to_rel[src_orig]\\n            dst = cuadra_id_to_rel[dst_orig]\\n            \\n            # Relación existente\\n            edges_rabia_cuadra.append((src, dst))\\n            cuadras_afectadas.add(dst_orig)# Guardar para contar luego\\n            \\n            # Nuevas relaciones\\n            edges_riesgo_proximidad.append((src, dst))  # rabies_case → cuadra\\n            edges_cercano_a_caso.append((dst, src))     # cuadra → rabies_case\\n\\n# Crear nuevas relaciones si existen\\nif edges_riesgo_proximidad:\\n    src, dst = zip(*edges_riesgo_proximidad)\\n    data[\"rabies_case\", \"riesgo_por_proximidad\", \"cuadra\"].edge_index = torch.tensor([src, dst], dtype=torch.long)\\n\\nif edges_cercano_a_caso:\\n    src, dst = zip(*edges_cercano_a_caso)\\n    data[\"cuadra\", \"cercano_a_caso\", \"rabies_case\"].edge_index = torch.tensor([src, dst], dtype=torch.long)\\n\\n#-------------- Mostrar en pantalla --------------------------\\nprint(f\"✔️ Casos de rabia dentro de una cuadra: {casos_dentro_cuadra}\")\\nprint(f\"❌ Casos de rabia fuera de una cuadra: {casos_fuera_cuadra}\")\\nprint(f\"🏘️ Cuadras afectadas por \\'riesgo_por_proximidad\\': {len(cuadras_afectadas)}\")\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# ---------------------------\n",
    "# 🦠 Caso de rabia → Cuadra (sjoin espacial)\n",
    "# ---------------------------\n",
    "\n",
    "# Eliminar columnas conflictivas si existen\n",
    "gdf_rabies_proj = gdf_rabies_proj.drop(columns=[\"index_left\", \"index_right\"], errors=\"ignore\")\n",
    "cuadras = cuadras.drop(columns=[\"index_left\", \"index_right\"], errors=\"ignore\")\n",
    "\n",
    "# Reparar geometrías inválidas\n",
    "cuadras[\"geometry\"] = cuadras[\"geometry\"].buffer(0)\n",
    "\n",
    "# Unificar CRS\n",
    "gdf_rabies_proj = gdf_rabies_proj.to_crs(cuadras.crs)\n",
    "\n",
    "# Spatial join (casos de rabia dentro de alguna cuadra)\n",
    "joined = gpd.sjoin(gdf_rabies_proj, cuadras, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "# Mapeos de índice original a índice relativo\n",
    "rabies_id_to_rel = {nid: i for i, nid in enumerate(data[\"rabies_case\"].node_index)}\n",
    "cuadra_id_to_rel = {nid: i for i, nid in enumerate(data[\"cuadra\"].node_index)}\n",
    "\n",
    "# Aristas caso de rabia → cuadra\n",
    "edges_rabia_cuadra = [] # Casos de rabia dentros de la cuadra\n",
    "edges_riesgo_proximidad = [] # Casos de rabia fuera de las cuadras\n",
    "# Arista cuadra -> caso de rabia\n",
    "edges_cercano_a_caso = []\n",
    "\n",
    "# |= Casos que cayeron dentro de una cuadra\n",
    "for _, row in joined.dropna(subset=[\"index_right\"]).iterrows():\n",
    "    src_orig = row.name\n",
    "    dst_orig = int(row[\"index_right\"])\n",
    "    if src_orig in rabies_id_to_rel and dst_orig in cuadra_id_to_rel:\n",
    "        src = rabies_id_to_rel[src_orig]\n",
    "        dst = cuadra_id_to_rel[dst_orig]\n",
    "        edges_rabia_cuadra.append((src, dst))\n",
    "\n",
    "# Construyendo la relacion\n",
    "if edges_rabia_cuadra:\n",
    "    src, dst = zip(*edges_rabia_cuadra)\n",
    "    data[\"rabies_case\", \"ocurre_en\", \"cuadra\"].edge_index = torch.tensor([src, dst], dtype=torch.long)# Convertir a tensor de aristas\n",
    "# Crear aristas inversas\n",
    "edge_index_ocurre_en = data[\"rabies_case\", \"ocurre_en\", \"cuadra\"].edge_index\n",
    "data[\"cuadra\", \"tiene_caso\", \"rabies_case\"].edge_index = edge_index_ocurre_en.flip(0)\n",
    "\n",
    "\n",
    "# |= Propagacion de los casos de rabia a las cuadras dentro del radio de RABIES_CASE_WITHOUT_CUADRA (100m)\n",
    "no_match = joined.copy()\n",
    "cuadras_afectadas = set()\n",
    "casos_dentro_cuadra = joined[\"index_right\"].notna().sum()\n",
    "casos_fuera_cuadra = joined[\"index_right\"].isna().sum()\n",
    "\n",
    "for _, row in no_match.iterrows():\n",
    "    src_orig = row.name\n",
    "    caso_point = row.geometry\n",
    "    dists = cuadras.geometry.distance(caso_point)\n",
    "    \n",
    "    # Filtrar las cuadras dentro del rango definido\n",
    "    cuadras_cercanas = dists[dists <= RABIES_CASE_PROXIMITY_CUADRA]\n",
    "\n",
    "    for dst_orig in cuadras_cercanas.index:\n",
    "        if src_orig in rabies_id_to_rel and dst_orig in cuadra_id_to_rel:\n",
    "            src = rabies_id_to_rel[src_orig]\n",
    "            dst = cuadra_id_to_rel[dst_orig]\n",
    "            \n",
    "            # Relación existente\n",
    "            edges_rabia_cuadra.append((src, dst))\n",
    "            cuadras_afectadas.add(dst_orig)# Guardar para contar luego\n",
    "            \n",
    "            # Nuevas relaciones\n",
    "            edges_riesgo_proximidad.append((src, dst))  # rabies_case → cuadra\n",
    "            edges_cercano_a_caso.append((dst, src))     # cuadra → rabies_case\n",
    "\n",
    "# Crear nuevas relaciones si existen\n",
    "if edges_riesgo_proximidad:\n",
    "    src, dst = zip(*edges_riesgo_proximidad)\n",
    "    data[\"rabies_case\", \"riesgo_por_proximidad\", \"cuadra\"].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "if edges_cercano_a_caso:\n",
    "    src, dst = zip(*edges_cercano_a_caso)\n",
    "    data[\"cuadra\", \"cercano_a_caso\", \"rabies_case\"].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "#-------------- Mostrar en pantalla --------------------------\n",
    "print(f\"✔️ Casos de rabia dentro de una cuadra: {casos_dentro_cuadra}\")\n",
    "print(f\"❌ Casos de rabia fuera de una cuadra: {casos_fuera_cuadra}\")\n",
    "print(f\"🏘️ Cuadras afectadas por 'riesgo_por_proximidad': {len(cuadras_afectadas)}\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodos en 'cuadra': 4296\n",
      "Relaciones y número de aristas:\n",
      "('cuadra', 'vecina_de', 'cuadra'): num_edges=64086\n",
      "('cuadra', 'reporta_a', 'health_post'): num_edges=4296\n",
      "('health_post', 'atiende_a', 'cuadra'): num_edges=4296\n",
      "('cuadra', 'cerca_de', 'water_channel'): num_edges=9228\n"
     ]
    }
   ],
   "source": [
    "# PARA VERIFICAR LA CANTIDAD DE NODOS Y ARISTAS\n",
    "#print(\"Nodos en 'rabies_case':\", data[\"rabies_case\"].num_nodes)\n",
    "print(\"Nodos en 'cuadra':\", data[\"cuadra\"].num_nodes)\n",
    "print(\"Relaciones y número de aristas:\")\n",
    "for etype in data.edge_types:\n",
    "    edge_storage = data[etype]\n",
    "    print(f\"{etype}: num_edges={getattr(edge_storage, 'num_edges', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Grafo heterogéneo guardado\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# GUARDAR EL GRAFO\n",
    "# ---------------------------\n",
    "torch.save(data, \"/home/pantro/Documentos/GITHUB/rabies-graph-neural-model/test_zamacola_heterograph_fase2.pt\")\n",
    "print(\"✅ Grafo heterogéneo guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /home/pantro/Documentos/GITHUB/doutoradoCS/myenv/lib/python3.12/site-packages (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando el grafo guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Grafo heterogéneo cargado correctamente\n",
      "True\n",
      "HeteroData(\n",
      "  cuadra={\n",
      "    x=[4296, 6],\n",
      "    cuadra_id=[4296],\n",
      "    node_index=[4296],\n",
      "  },\n",
      "  health_post={\n",
      "    x=[4, 2],\n",
      "    name=[4],\n",
      "    node_index=[4],\n",
      "  },\n",
      "  water_channel={\n",
      "    x=[218, 2],\n",
      "    ident=[218],\n",
      "    node_index=[218],\n",
      "  },\n",
      "  rabies_case={\n",
      "    x=[161, 2],\n",
      "    name=[161],\n",
      "    year=[161],\n",
      "    node_index=[161],\n",
      "  },\n",
      "  (cuadra, vecina_de, cuadra)={ edge_index=[2, 64086] },\n",
      "  (cuadra, reporta_a, health_post)={\n",
      "    edge_index=[2, 4296],\n",
      "    edge_attr=[4296, 1],\n",
      "  },\n",
      "  (health_post, atiende_a, cuadra)={\n",
      "    edge_index=[2, 4296],\n",
      "    edge_attr=[4296, 1],\n",
      "  },\n",
      "  (cuadra, cerca_de, water_channel)={\n",
      "    edge_index=[2, 9228],\n",
      "    edge_attr=[9228, 1],\n",
      "  },\n",
      "  (rabies_case, ocurre_en, cuadra)={ edge_index=[2, 91] },\n",
      "  (cuadra, tiene_caso, rabies_case)={ edge_index=[2, 91] },\n",
      "  (rabies_case, riesgo_por_proximidad, cuadra)={ edge_index=[2, 1237] },\n",
      "  (cuadra, cercano_a_caso, rabies_case)={ edge_index=[2, 1237] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Cargar el grafo\n",
    "data = torch.load(\"/home/pantro/Documentos/GITHUB/rabies-graph-neural-model/zamacola_heterograph_fase2.pt\", weights_only=False)\n",
    "\n",
    "print(\"✅ Grafo heterogéneo cargado correctamente\")\n",
    "print(isinstance(data, HeteroData))  # Debería imprimir: True\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar en formato para Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado nodos: cuadra -> (4296, 9)\n",
      "Guardado nodos: health_post -> (4, 3)\n",
      "Guardado nodos: water_channel -> (218, 3)\n",
      "Guardado aristas: ('cuadra', 'vecina_de', 'cuadra') -> (64086, 5)\n",
      "Guardado aristas: ('cuadra', 'reporta_a', 'health_post') -> (4296, 6)\n",
      "Guardado aristas: ('health_post', 'atiende_a', 'cuadra') -> (4296, 6)\n",
      "Guardado aristas: ('cuadra', 'cerca_de', 'water_channel') -> (9228, 6)\n",
      "\n",
      "✅ Exportación completa. Los archivos están en: /home/pantro/Documentos/GITHUB/rabies-graph-neural-model/neo4j_csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def heterodata_to_neo4j_csv(data, output_dir=\"neo4j_csv\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Guardar nodos\n",
    "    for node_type in data.node_types:\n",
    "        node_data = data[node_type]\n",
    "\n",
    "        # Asegurarse de que haya atributos\n",
    "        if hasattr(node_data, 'x') and node_data.x is not None:\n",
    "            df = pd.DataFrame(node_data.x.cpu().numpy())\n",
    "            df.columns = [f\"attr{i}\" for i in range(df.shape[1])]\n",
    "        else:\n",
    "            num_nodes = data[node_type].num_nodes\n",
    "            df = pd.DataFrame(index=range(num_nodes))  # Nodo sin atributos\n",
    "\n",
    "        # Agregar columna de ID (requerida por Neo4j)\n",
    "        df[f\"{node_type}_id\"] = df.index\n",
    "        df.to_csv(os.path.join(output_dir, f\"nodes_{node_type}.csv\"), index=False)\n",
    "        print(f\"Guardado nodos: {node_type} -> {df.shape}\")\n",
    "\n",
    "    # Guardar aristas\n",
    "    for edge_type in data.edge_types:\n",
    "        src_type, rel_type, dst_type = edge_type\n",
    "        edge_index = data[edge_type].edge_index.cpu().numpy()\n",
    "\n",
    "        edge_df = pd.DataFrame({\n",
    "            \"source\": edge_index[0],\n",
    "            \"target\": edge_index[1],\n",
    "            \"type\": rel_type,\n",
    "            \"source_type\": src_type,\n",
    "            \"target_type\": dst_type\n",
    "        })\n",
    "\n",
    "        # Agregar atributos de aristas si existen\n",
    "        if 'edge_attr' in data[edge_type]:\n",
    "            edge_attrs = data[edge_type]['edge_attr'].cpu().numpy()\n",
    "            edge_attr_df = pd.DataFrame(edge_attrs)\n",
    "            edge_df = pd.concat([edge_df, edge_attr_df], axis=1)\n",
    "\n",
    "        filename = f\"edges_{src_type}_{rel_type}_{dst_type}.csv\"\n",
    "        edge_df.to_csv(os.path.join(output_dir, filename), index=False)\n",
    "        print(f\"Guardado aristas: {edge_type} -> {edge_df.shape}\")\n",
    "\n",
    "    print(\"\\n✅ Exportación completa. Los archivos están en:\", os.path.abspath(output_dir))\n",
    "\n",
    "\n",
    "# Llamar a la función\n",
    "heterodata_to_neo4j_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armar datos para el random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import nearest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_VAL\n",
    "rf_gdf_rabies = gdf_rabies_train_val.copy()\n",
    "\n",
    "# Cambiar a \"EPSG:32719\"\n",
    "rf_gdf_rabies_proj = rf_gdf_rabies.to_crs(\"EPSG:32719\")\n",
    "rf_gdf_economic_income_proj = gdf_economic_income.to_crs(\"EPSG:32719\")\n",
    "rf_gdf_health_posts_proj = gdf_health_posts.to_crs(\"EPSG:32719\")\n",
    "rf_gdf_water_channels_proj = gdf_water_channels.to_crs(\"EPSG:32719\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "0    4221\n",
      "1      75\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuadra_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>centroid</th>\n",
       "      <th>ingreso_B</th>\n",
       "      <th>ingreso_C</th>\n",
       "      <th>ingreso_D</th>\n",
       "      <th>ingreso_E</th>\n",
       "      <th>num_rabies_cases_in_cuadra</th>\n",
       "      <th>dist_to_nearest_health_post</th>\n",
       "      <th>dist_to_nearest_water_channel</th>\n",
       "      <th>min_dist_to_rabies_case</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4.100-1</td>\n",
       "      <td>POLYGON ((224268.545 8190480.422, 224175.196 8...</td>\n",
       "      <td>POINT (224132.601 8190627.741)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1815.732788</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4.100-10</td>\n",
       "      <td>POLYGON ((223983.171 8191303.516, 223985.935 8...</td>\n",
       "      <td>POINT (223989.033 8191286.737)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1610.846277</td>\n",
       "      <td>415.993967</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4.100-11</td>\n",
       "      <td>POLYGON ((223991.362 8191312.242, 224167.947 8...</td>\n",
       "      <td>POINT (224080.678 8191340.585)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1787.481405</td>\n",
       "      <td>476.290826</td>\n",
       "      <td>32.510141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.4.100-12</td>\n",
       "      <td>POLYGON ((223736.505 8191347.126, 223726.379 8...</td>\n",
       "      <td>POINT (223784.996 8191332.717)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1521.736024</td>\n",
       "      <td>339.202959</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4.100-2</td>\n",
       "      <td>POLYGON ((223940.104 8190652.198, 223924.309 8...</td>\n",
       "      <td>POINT (223949.842 8190607.880)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1778.237966</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cuadra_id                                           geometry  \\\n",
       "0   1.4.100-1  POLYGON ((224268.545 8190480.422, 224175.196 8...   \n",
       "1  1.4.100-10  POLYGON ((223983.171 8191303.516, 223985.935 8...   \n",
       "2  1.4.100-11  POLYGON ((223991.362 8191312.242, 224167.947 8...   \n",
       "3  1.4.100-12  POLYGON ((223736.505 8191347.126, 223726.379 8...   \n",
       "4   1.4.100-2  POLYGON ((223940.104 8190652.198, 223924.309 8...   \n",
       "\n",
       "                         centroid  ingreso_B  ingreso_C  ingreso_D  ingreso_E  \\\n",
       "0  POINT (224132.601 8190627.741)      False      False       True      False   \n",
       "1  POINT (223989.033 8191286.737)      False      False       True      False   \n",
       "2  POINT (224080.678 8191340.585)      False      False       True      False   \n",
       "3  POINT (223784.996 8191332.717)      False      False       True      False   \n",
       "4  POINT (223949.842 8190607.880)      False      False       True      False   \n",
       "\n",
       "   num_rabies_cases_in_cuadra  dist_to_nearest_health_post  \\\n",
       "0                           0                  1815.732788   \n",
       "1                           0                  1610.846277   \n",
       "2                           0                  1787.481405   \n",
       "3                           0                  1521.736024   \n",
       "4                           0                  1778.237966   \n",
       "\n",
       "   dist_to_nearest_water_channel  min_dist_to_rabies_case  y  \n",
       "0                    9999.000000              9999.000000  0  \n",
       "1                     415.993967              9999.000000  0  \n",
       "2                     476.290826                32.510141  0  \n",
       "3                     339.202959              9999.000000  0  \n",
       "4                    9999.000000              9999.000000  0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuadras = rf_gdf_economic_income_proj.copy()\n",
    "\n",
    "cuadras[\"centroid\"] = cuadras.geometry.centroid\n",
    "\n",
    "# One-hot encoding ingreso económico\n",
    "cuadras = pd.get_dummies(cuadras, columns=[\"ingreso_economico\"], prefix=\"ingreso\")\n",
    "\n",
    "# Casos de rabia dentro de la cuadra\n",
    "cuadras[\"num_rabies_cases_in_cuadra\"] = cuadras.geometry.apply(\n",
    "    lambda poly: rabies[rabies.within(poly)].shape[0]\n",
    ")\n",
    "\n",
    "\n",
    "# Crear una lista con las geometrías de los puestos de salud (POINT)\n",
    "health_points = rf_gdf_health_posts_proj.geometry.unary_union\n",
    "# Calcular la distancia mínima a cada cuadra\n",
    "cuadras['dist_to_nearest_health_post'] = cuadras.geometry.apply(\n",
    "    lambda g: g.distance(nearest_points(g, health_points)[1])\n",
    ")\n",
    "\n",
    "# Parámetro: distancia máxima para considerar la torrenteras como relevantes\n",
    "MAX_DIST = 500  # en metros\n",
    "# Unimos las torrenteras en una sola geometría multiparte\n",
    "torrenteras_geom = rf_gdf_water_channels_proj.geometry.unary_union\n",
    "# Calcular distancia a torrenteras (si > MAX_DIST => 9999)\n",
    "cuadras['dist_to_nearest_water_channel'] = cuadras.geometry.apply(\n",
    "    lambda g: g.distance(torrenteras_geom) if g.distance(torrenteras_geom) <= MAX_DIST else 9999\n",
    ")\n",
    "\n",
    "CUADRA_PROXIMITY_RABIES_CASE_RADIUS = 100\n",
    "# Distancia al caso de rabia más cercano en 100 m\n",
    "def min_dist_to_case(poly_centroid, rabies_points, max_dist):\n",
    "    distances = rabies_points.distance(poly_centroid)\n",
    "    close = distances[distances <= max_dist]\n",
    "    return close.min() if not close.empty else np.nan\n",
    "cuadras[\"min_dist_to_rabies_case\"] = cuadras[\"centroid\"].apply(\n",
    "    lambda p: min_dist_to_case(p, rabies.geometry, CUADRA_PROXIMITY_RABIES_CASE_RADIUS)\n",
    ")\n",
    "# Rellenar NaN con un valor alto para que redes neuronales lo manejen mejor\n",
    "cuadras[\"min_dist_to_rabies_case\"] = cuadras[\"min_dist_to_rabies_case\"].fillna(9999)\n",
    "\n",
    "\n",
    "# Creando etiqueta Y\n",
    "cuadras['y'] = (cuadras['num_rabies_cases_in_cuadra'] > 0).astype(int)\n",
    "\n",
    "print(cuadras['y'].value_counts())\n",
    "cuadras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando centroide\n",
    "cuadras.drop(columns=['centroid'], inplace=True)\n",
    "\n",
    "cuadras.to_file('rf_cuadras.gpkg', driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
